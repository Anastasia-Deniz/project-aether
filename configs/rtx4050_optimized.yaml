# Project Aether - Optimized Config for RTX 4050 (6GB VRAM)
# This config is tuned to maximize performance while staying within memory limits

# GPU Memory Budget: ~5.5GB (leaving headroom)
# LCM Model: ~2.5GB
# Latent encoder + Policy: ~0.1GB
# Batch processing: ~2GB
# Safety margin: ~1GB

# ============================================================
# COMPUTE SETTINGS
# ============================================================
compute:
  device: "cuda"
  dtype: "float16"  # CRITICAL: Half precision saves ~50% VRAM
  seed: 42

# ============================================================
# MODEL SETTINGS (Memory Optimized)
# ============================================================
model:
  # Using LCM (Latent Consistency Model) for faster inference
  model_id: "rupeshs/LCM-runwayml-stable-diffusion-v1-5"
  # LCM works with 4-8 steps - much faster than standard SD!
  # Quality impact is minimal, training speed ~3x faster
  num_inference_steps: 8  # LCM optimal range: 4-8 steps
  guidance_scale: 7.5
  latent_channels: 4
  latent_size: 64

# ============================================================
# ENVIRONMENT SETTINGS
# ============================================================
env:
  # Steering dimension (256 is good balance)
  steering_dim: 256
  
  # Action constraints
  max_action_norm: 0.1
  
  # Intervention window (adjusted for LCM's 8 steps)
  intervention_start: 2   # ~25% of generation
  intervention_end: 6     # ~75% of generation
  
  # Use latent encoder to reduce observation space
  use_latent_encoder: true
  encoded_latent_dim: 256

# ============================================================
# PPO HYPERPARAMETERS (Memory Optimized)
# ============================================================
ppo:
  learning_rate: 3.0e-4
  
  # REDUCED rollout steps to fit in memory
  # Original: 2048, Optimized: 512
  # Compensate with more frequent updates
  n_steps: 512
  
  # REDUCED batch size for memory
  # Original: 64, Optimized: 32
  batch_size: 32
  
  # Keep epochs same
  n_epochs: 10
  
  gamma: 0.99
  gae_lambda: 0.95
  clip_range: 0.2
  vf_coef: 0.5
  ent_coef: 0.01
  max_grad_norm: 0.5
  
  # Adjust total timesteps (can increase for better results)
  total_timesteps: 100000  # Start smaller, scale up if stable

# ============================================================
# POLICY NETWORK
# ============================================================
policy:
  # Smaller hidden dims for memory efficiency
  hidden_dims: [256, 128]  # Reduced from [512, 256]
  activation: "relu"
  latent_encoder_dim: 256

# ============================================================
# REWARD SETTINGS
# ============================================================
reward:
  lambda_transport: 0.5
  safety_classifier: null
  # Update this path after running train_probes.py
  probe_path: null

# ============================================================
# DATA SETTINGS (Memory Optimized)
# ============================================================
data:
  # Smaller sample sizes for initial experiments
  num_safe_samples: 50
  num_unsafe_samples: 50
  
  i2p_categories:
    - "violence"
    - "sexual"
    - "shocking"
  
  min_inappropriate_pct: 30.0
  cache_dir: "./data/cache"

# ============================================================
# TRAINING SETTINGS
# ============================================================
training:
  experiment_name: "aether_rtx4050"
  
  # More frequent logging/saving due to smaller rollouts
  log_interval: 5
  save_interval: 5000
  
  # Early stopping
  early_stopping:
    enabled: true
    patience: 20000
    min_delta: 0.01
    metric: "rollout/ep_rew_mean"

# ============================================================
# LOGGING
# ============================================================
wandb:
  enabled: false  # Set to true if you have W&B account
  project: "project-aether"
  entity: null
  tags:
    - "rtx4050"
    - "6gb"
    - "optimized"

# ============================================================
# PATHS
# ============================================================
paths:
  checkpoints: "./checkpoints"
  outputs: "./outputs"
  data: "./data"
  latents: "./data/latents"

