{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Project Aether - Google Colab Setup\n",
        "\n",
        "This notebook sets up and runs Project Aether on Google Colab with GPU support.\n",
        "\n",
        "## Features\n",
        "- Automatic GPU detection and setup\n",
        "- Model downloads (Stable Diffusion 1.4 - less censored for research)\n",
        "- All three phases: Probe Training, PPO Training, Evaluation\n",
        "- **⚡ Fast training config** (2-3 hours instead of 8 hours) - automatically uses optimized settings\n",
        "- **Empirical layer sensitivity measurement** (FID & SSR) for optimal intervention points\n",
        "- Optimized for Colab's T4 GPU (16GB VRAM)\n",
        "- **Nudity-focused** content filtering for clearer concept boundaries\n",
        "- Image visualization to verify probe accuracy\n",
        "\n",
        "## Important Notes\n",
        "- **Model:** Uses `CompVis/stable-diffusion-v1-4` (less censored than SD 1.5)\n",
        "- **Focus:** Nudity-only content (not gore/violence) for better probe training\n",
        "- **Filtering:** Strict thresholds (≥50% nudity, ≥60% inappropriate, hard prompts only)\n",
        "\n",
        "## References\n",
        "- **FID Metric:** Heusel et al. (2017). \"GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium.\" NeurIPS 2017.\n",
        "- **Linear Probing:** Alain & Bengio (2016). \"Understanding Intermediate Layers Using Linear Classifier Probes.\" arXiv:1610.01644.\n",
        "- **PPO:** Schulman et al. (2017). \"Proximal Policy Optimization Algorithms.\" arXiv:1707.06347.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install PyTorch with CUDA 12.1 (Colab default)\n",
        "print(\"Installing PyTorch...\")\n",
        "!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121 -q\n",
        "\n",
        "# Install other dependencies\n",
        "print(\"Installing core dependencies...\")\n",
        "!pip install diffusers transformers accelerate safetensors -q\n",
        "!pip install gymnasium numpy scikit-learn matplotlib tqdm -q\n",
        "!pip install pyyaml pillow lpips -q\n",
        "!pip install datasets -q  # For I2P dataset\n",
        "!pip install pytorch-fid -q  # For FID metric (Heusel et al., 2017)\n",
        "\n",
        "print(\"✓ All dependencies installed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Clone Repository or Upload Files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option A: Clone from GitHub\n",
        "import os\n",
        "if not os.path.exists('project-aether'):\n",
        "    print(\"Cloning repository...\")\n",
        "    !git clone https://github.com/Anastasia-Deniz/project-aether.git\n",
        "    print(\"✓ Repository cloned!\")\n",
        "else:\n",
        "    print(\"✓ Repository already exists, skipping clone\")\n",
        "\n",
        "%cd project-aether\n",
        "\n",
        "# Option B: If you uploaded files manually, uncomment:\n",
        "# %cd /content/project-aether\n",
        "\n",
        "# Verify we're in the right directory\n",
        "import sys\n",
        "from pathlib import Path\n",
        "if Path('scripts/train_ppo.py').exists():\n",
        "    print(f\"✓ Project structure verified! Working directory: {Path.cwd()}\")\n",
        "else:\n",
        "    print(\"⚠ Warning: Project structure not found. Make sure you're in the project-aether directory.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5.25: (Optional) Verify Labels ⭐ NEW - RECOMMENDED\n",
        "\n",
        "**Important:** Before training probes, verify that generated images match their labels!\n",
        "\n",
        "This step uses CLIP to verify that images actually match their prompt-based labels. This is critical because SD 1.4 may generate safe images from unsafe prompts (censorship), leading to poor separability.\n",
        "\n",
        "**Note:** This takes ~10-20 minutes but significantly improves probe accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify labels using CLIP-based safety classifier\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"VERIFYING LABELS\")\n",
        "print(\"=\"*60)\n",
        "print(\"This step:\")\n",
        "print(\"  - Decodes images from latents\")\n",
        "print(\"  - Uses CLIP to verify labels match images\")\n",
        "print(\"  - Filters out mismatched samples\")\n",
        "print(\"  - Creates cleaned dataset\")\n",
        "print(\"  - Estimated time: 10-20 minutes\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "latents_dirs = sorted(Path('data/latents').glob('run_*'), key=lambda p: p.stat().st_mtime)\n",
        "if latents_dirs:\n",
        "    latest_latents = latents_dirs[-1]\n",
        "    print(f\"\\nUsing latents from: {latest_latents}\")\n",
        "    \n",
        "    # Check if already verified\n",
        "    verified_dir = latest_latents.parent / f\"{latest_latents.name}_verified\"\n",
        "    if verified_dir.exists():\n",
        "        print(f\"\\n✓ Verified dataset already exists: {verified_dir}\")\n",
        "        print(\"  Skipping verification. To re-verify, delete this directory first.\")\n",
        "    else:\n",
        "        print(f\"\\nVerifying labels...\")\n",
        "        \n",
        "        import torch\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        \n",
        "        !python scripts/verify_labels.py \\\n",
        "            --latents_dir {latest_latents} \\\n",
        "            --method clip \\\n",
        "            --threshold 0.7 \\\n",
        "            --device {device}\n",
        "        \n",
        "        # Check if verification succeeded\n",
        "        if verified_dir.exists():\n",
        "            print(f\"\\n✓ Verification complete! Verified dataset: {verified_dir}\")\n",
        "            \n",
        "            # Show statistics\n",
        "            mismatch_file = verified_dir / \"mismatch_report.json\"\n",
        "            if mismatch_file.exists():\n",
        "                import json\n",
        "                with open(mismatch_file) as f:\n",
        "                    mismatches = json.load(f)\n",
        "                print(f\"  Mismatches found: {len(mismatches)}\")\n",
        "                \n",
        "                if len(mismatches) > 0:\n",
        "                    print(f\"\\n⚠ Warning: {len(mismatches)} samples had mismatched labels!\")\n",
        "                    print(\"  Review mismatch_report.json for details.\")\n",
        "                    print(\"  Consider:\")\n",
        "                    print(\"    - Using stricter prompt filtering\")\n",
        "                    print(\"    - Using a more explicit model\")\n",
        "                    print(\"    - Manually reviewing generated images\")\n",
        "        else:\n",
        "            print(\"\\n⚠ Warning: Verification may have failed. Check for errors above.\")\n",
        "else:\n",
        "    print(\"⚠ Error: No latents found! Run Step 4 first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Verify GPU and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Verify GPU\n",
        "print(\"=\"*60)\n",
        "print(\"GPU VERIFICATION\")\n",
        "print(\"=\"*60)\n",
        "cuda_available = torch.cuda.is_available()\n",
        "print(f\"CUDA available: {cuda_available}\")\n",
        "\n",
        "if cuda_available:\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    vram_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f\"GPU: {gpu_name}\")\n",
        "    print(f\"VRAM: {vram_gb:.2f} GB\")\n",
        "    \n",
        "    if vram_gb < 12:\n",
        "        print(\"⚠ Warning: Less than 12GB VRAM. Consider reducing batch sizes.\")\n",
        "    else:\n",
        "        print(\"✓ Sufficient VRAM for Colab-optimized config\")\n",
        "else:\n",
        "    print(\"⚠ Warning: No GPU detected! Training will be very slow on CPU.\")\n",
        "    print(\"  Make sure Runtime > Change runtime type > Hardware accelerator = GPU\")\n",
        "\n",
        "# Add project to path\n",
        "project_root = Path.cwd()\n",
        "sys.path.insert(0, str(project_root))\n",
        "print(f\"\\nProject root: {project_root}\")\n",
        "\n",
        "# Create necessary directories\n",
        "print(\"\\nCreating directories...\")\n",
        "dirs = ['data/latents', 'checkpoints/probes', 'outputs/ppo', 'outputs/evaluation', 'outputs/visualizations']\n",
        "for d in dirs:\n",
        "    Path(d).mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"  ✓ {d}\")\n",
        "\n",
        "print(\"\\n✓ Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Phase 1 - Collect Latents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect latents for probe training\n",
        "# Colab T4 has 16GB VRAM, so we can use larger batch sizes\n",
        "# Using SD 1.4 (20 steps) - less censored than SD 1.5, better for research\n",
        "# Focus on nudity only with strict quality thresholds\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"PHASE 1: COLLECTING LATENTS\")\n",
        "print(\"=\"*60)\n",
        "print(\"This will:\")\n",
        "print(\"  - Download Stable Diffusion 1.4 model (~4GB)\")\n",
        "print(\"  - Generate 100 safe and 100 unsafe images\")\n",
        "print(\"  - Save latents at each timestep\")\n",
        "print(\"  - Estimated time: 30-60 minutes\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check if CUDA is available\n",
        "import torch\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"⚠ Warning: CUDA not available. This will be very slow!\")\n",
        "    device = \"cpu\"\n",
        "else:\n",
        "    device = \"cuda\"\n",
        "\n",
        "!python scripts/collect_latents.py \\\n",
        "    --num_samples 100 \\\n",
        "    --num_steps 20 \\\n",
        "    --device {device} \\\n",
        "    --model_id CompVis/stable-diffusion-v1-4 \\\n",
        "    --focus_nudity \\\n",
        "    --hard_only \\\n",
        "    --min_inappropriate_pct 60.0 \\\n",
        "    --min_nudity_pct 50.0 \\\n",
        "    --save_images\n",
        "\n",
        "# Verify output\n",
        "from pathlib import Path\n",
        "latents_dirs = sorted(Path('data/latents').glob('run_*'), key=lambda p: p.stat().st_mtime)\n",
        "if latents_dirs:\n",
        "    latest = latents_dirs[-1]\n",
        "    print(f\"\\n✓ Latents collected! Output: {latest}\")\n",
        "    \n",
        "    # Count files\n",
        "    latent_files = list(latest.glob('latents/timestep_*.npz'))\n",
        "    print(f\"  Found {len(latent_files)} timestep files\")\n",
        "else:\n",
        "    print(\"\\n⚠ Warning: No latents directory found. Check for errors above.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Phase 1 - Train Probes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train linear probes\n",
        "# Find the latest latents directory\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"PHASE 1: TRAINING LINEAR PROBES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "latents_dirs = sorted(Path('data/latents').glob('run_*'), key=lambda p: p.stat().st_mtime)\n",
        "if latents_dirs:\n",
        "    latest_latents = latents_dirs[-1]\n",
        "    print(f\"Using latents from: {latest_latents}\")\n",
        "    \n",
        "    # Check if empirical measurements exist\n",
        "    use_empirical = False\n",
        "    quality_file = latest_latents / \"quality_measurements.json\"\n",
        "    effectiveness_file = latest_latents / \"effectiveness_measurements.json\"\n",
        "    \n",
        "    if quality_file.exists() and effectiveness_file.exists():\n",
        "        print(\"✓ Found empirical measurements! Using them for better accuracy.\")\n",
        "        use_empirical = True\n",
        "    else:\n",
        "        print(\"Using improved heuristics (faster). For better accuracy, run Step 5.5 first.\")\n",
        "    \n",
        "    # Train probes\n",
        "    if use_empirical:\n",
        "        print(\"\\nTraining with empirical measurements...\")\n",
        "        !python scripts/train_probes.py --latents_dir {latest_latents} --use_empirical\n",
        "    else:\n",
        "        print(\"\\nTraining with heuristics...\")\n",
        "        !python scripts/train_probes.py --latents_dir {latest_latents}\n",
        "    \n",
        "    # Print probe results summary\n",
        "    probe_dirs = sorted(Path('checkpoints/probes').glob('run_*'), key=lambda p: p.stat().st_mtime)\n",
        "    if probe_dirs:\n",
        "        latest_probe = probe_dirs[-1]\n",
        "        metrics_file = latest_probe / 'probe_metrics.json'\n",
        "        sensitivity_file = latest_probe / 'sensitivity_scores.json'\n",
        "        \n",
        "        if metrics_file.exists():\n",
        "            with open(metrics_file) as f:\n",
        "                metrics = json.load(f)\n",
        "            \n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"PROBE ACCURACY SUMMARY\")\n",
        "            print(\"=\"*60)\n",
        "            best_acc = 0\n",
        "            best_t = None\n",
        "            for t in sorted(metrics.keys(), key=int):\n",
        "                acc = metrics[t]['test_acc']\n",
        "                print(f\"Timestep {t:2d}: {acc:.3f} ({acc*100:5.1f}%)\")\n",
        "                if acc > best_acc:\n",
        "                    best_acc = acc\n",
        "                    best_t = t\n",
        "            \n",
        "            print(f\"\\n✓ Best accuracy: {best_acc:.3f} at timestep {best_t}\")\n",
        "            \n",
        "            # Check sensitivity scores\n",
        "            if sensitivity_file.exists():\n",
        "                with open(sensitivity_file) as f:\n",
        "                    sens_data = json.load(f)\n",
        "                \n",
        "                if 'optimal_window' in sens_data:\n",
        "                    window = sens_data['optimal_window']\n",
        "                    print(f\"\\n✓ Recommended intervention window: steps {window.get('start', '?')} to {window.get('end', '?')}\")\n",
        "                    if 'top_timesteps' in window:\n",
        "                        print(f\"  Top timesteps: {window['top_timesteps']}\")\n",
        "        else:\n",
        "            print(\"⚠ Warning: probe_metrics.json not found\")\n",
        "    else:\n",
        "        print(\"⚠ Warning: No probe directories created. Check for errors above.\")\n",
        "else:\n",
        "    print(\"⚠ Error: No latents found! Run Step 4 first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5.5: (Optional) Measure Empirical Layer Sensitivity ⭐ NEW\n",
        "\n",
        "**Recommended for best results:** Measure FID and SSR empirically instead of using heuristics.\n",
        "\n",
        "This step runs small steering experiments to measure:\n",
        "- **Quality preservation**: FID between steered and unsteered images (Heusel et al., 2017)\n",
        "- **Steering effectiveness**: SSR improvement from steering\n",
        "\n",
        "**Note:** This takes additional time (~30-60 min) but provides more accurate sensitivity scores.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Measure empirical layer sensitivity (FID and SSR)\n",
        "# This improves the quality of layer sensitivity analysis\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"MEASURING EMPIRICAL LAYER SENSITIVITY\")\n",
        "print(\"=\"*60)\n",
        "print(\"This step:\")\n",
        "print(\"  - Runs small steering experiments at each timestep\")\n",
        "print(\"  - Measures FID (quality preservation)\")\n",
        "print(\"  - Measures SSR (steering effectiveness)\")\n",
        "print(\"  - Estimated time: 30-60 minutes\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "latents_dirs = sorted(Path('data/latents').glob('run_*'), key=lambda p: p.stat().st_mtime)\n",
        "probe_dirs = sorted(Path('checkpoints/probes').glob('run_*'), key=lambda p: p.stat().st_mtime)\n",
        "\n",
        "if latents_dirs:\n",
        "    latest_latents = latents_dirs[-1]\n",
        "    print(f\"\\nUsing latents from: {latest_latents}\")\n",
        "    \n",
        "    # Use probe from Step 5 if available\n",
        "    probe_path = None\n",
        "    if probe_dirs:\n",
        "        latest_probe = probe_dirs[-1] / 'pytorch'\n",
        "        if latest_probe.exists():\n",
        "            probe_path = str(latest_probe)\n",
        "            print(f\"Using probe: {probe_path}\")\n",
        "        else:\n",
        "            print(\"⚠ Warning: Probe directory exists but pytorch/ subdirectory not found\")\n",
        "    else:\n",
        "        print(\"⚠ Warning: No probes found. Running without probe (will use random steering)\")\n",
        "    \n",
        "    # Check if already measured\n",
        "    quality_file = latest_latents / \"quality_measurements.json\"\n",
        "    effectiveness_file = latest_latents / \"effectiveness_measurements.json\"\n",
        "    \n",
        "    if quality_file.exists() and effectiveness_file.exists():\n",
        "        print(\"\\n✓ Measurements already exist! Skipping measurement.\")\n",
        "        print(f\"  Quality: {quality_file}\")\n",
        "        print(f\"  Effectiveness: {effectiveness_file}\")\n",
        "        print(\"\\nTo re-measure, delete these files first.\")\n",
        "    else:\n",
        "        print(f\"\\nMeasuring empirical sensitivity...\")\n",
        "        print(\"This may take 30-60 minutes...\")\n",
        "        \n",
        "        import torch\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        \n",
        "        if probe_path:\n",
        "            !python scripts/measure_layer_sensitivity.py \\\n",
        "                --latents_dir {latest_latents} \\\n",
        "                --num_samples 20 \\\n",
        "                --device {device} \\\n",
        "                --probe_path {probe_path}\n",
        "        else:\n",
        "            !python scripts/measure_layer_sensitivity.py \\\n",
        "                --latents_dir {latest_latents} \\\n",
        "                --num_samples 20 \\\n",
        "                --device {device}\n",
        "        \n",
        "        # Verify measurements were created\n",
        "        quality_file = latest_latents / \"quality_measurements.json\"\n",
        "        effectiveness_file = latest_latents / \"effectiveness_measurements.json\"\n",
        "        \n",
        "        if quality_file.exists():\n",
        "            print(f\"\\n✓ Quality measurements saved: {quality_file}\")\n",
        "        else:\n",
        "            print(f\"\\n⚠ Warning: Quality measurements not found\")\n",
        "        \n",
        "        if effectiveness_file.exists():\n",
        "            print(f\"✓ Effectiveness measurements saved: {effectiveness_file}\")\n",
        "        else:\n",
        "            print(f\"⚠ Warning: Effectiveness measurements not found\")\n",
        "        \n",
        "        if quality_file.exists() and effectiveness_file.exists():\n",
        "            print(\"\\n✓ Measurements complete! Now re-run Step 5 to use them.\")\n",
        "        else:\n",
        "            print(\"\\n⚠ Some measurements missing. Check for errors above.\")\n",
        "else:\n",
        "    print(\"⚠ Error: No latents found! Run Step 4 first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Visualize Generated Images & Verify Probe Accuracy ⭐ NEW\n",
        "\n",
        "**Important:** Before training PPO, verify that the generated images match their labels!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate images from collected latents to verify what was actually generated\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"GENERATING IMAGES FROM LATENTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "latents_dirs = sorted(Path('data/latents').glob('run_*'), key=lambda p: p.stat().st_mtime)\n",
        "if latents_dirs:\n",
        "    latest_latents = latents_dirs[-1]\n",
        "    print(f\"Using latents from: {latest_latents}\")\n",
        "    \n",
        "    # Check if images already exist\n",
        "    viewer_path = latest_latents / \"images_t20/viewer.html\"\n",
        "    if viewer_path.exists():\n",
        "        print(\"\\n✓ Images already generated! Skipping...\")\n",
        "        print(f\"  Viewer: {viewer_path}\")\n",
        "    else:\n",
        "        print(\"\\nGenerating images from final timestep (t=20)...\")\n",
        "        print(\"This may take 5-10 minutes...\")\n",
        "        \n",
        "        import torch\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        \n",
        "        !python scripts/generate_images_from_latents.py \\\n",
        "            --latents_dir {latest_latents} \\\n",
        "            --timestep 20 \\\n",
        "            --num_samples 50 \\\n",
        "            --device {device}\n",
        "        \n",
        "        # Check if HTML viewer was created\n",
        "        viewer_path = latest_latents / \"images_t20/viewer.html\"\n",
        "        if viewer_path.exists():\n",
        "            print(f\"\\n✓ Images generated! Viewer: {viewer_path}\")\n",
        "        else:\n",
        "            print(\"\\n⚠ Warning: HTML viewer not found. Check for errors above.\")\n",
        "    \n",
        "    # Show how to view\n",
        "    if viewer_path.exists():\n",
        "        print(\"\\nTo view images in Colab, run the next cell!\")\n",
        "else:\n",
        "    print(\"⚠ Error: No latents found! Run Step 4 first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### View Images in Colab\n",
        "\n",
        "Display the HTML viewer directly in the notebook:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display HTML viewer in Colab\n",
        "from IPython.display import HTML, display\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "latents_dirs = sorted(Path('data/latents').glob('run_*'), key=os.path.getmtime)\n",
        "if latents_dirs:\n",
        "    latest_latents = latents_dirs[-1]\n",
        "    viewer_path = latest_latents / \"images_t20/viewer.html\"\n",
        "    \n",
        "    if viewer_path.exists():\n",
        "        with open(viewer_path, 'r', encoding='utf-8') as f:\n",
        "            html_content = f.read()\n",
        "        display(HTML(html_content))\n",
        "    else:\n",
        "        print(\"Viewer not found. Run the previous cell first.\")\n",
        "else:\n",
        "    print(\"No latents found!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize Probe Results\n",
        "\n",
        "See which images are correctly/incorrectly classified by the probe:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize probe predictions on images\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"VISUALIZING PROBE RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "latents_dirs = sorted(Path('data/latents').glob('run_*'), key=lambda p: p.stat().st_mtime)\n",
        "probe_dirs = sorted(Path('checkpoints/probes').glob('run_*'), key=lambda p: p.stat().st_mtime)\n",
        "\n",
        "if latents_dirs and probe_dirs:\n",
        "    latest_latents = latents_dirs[-1]\n",
        "    latest_probe = probe_dirs[-1]\n",
        "    probe_pytorch = latest_probe / 'pytorch'\n",
        "    \n",
        "    # Find best timestep from sensitivity analysis\n",
        "    best_timestep = 4  # Default\n",
        "    sensitivity_file = latest_probe / 'sensitivity_scores.json'\n",
        "    \n",
        "    if sensitivity_file.exists():\n",
        "        with open(sensitivity_file) as f:\n",
        "            sens_data = json.load(f)\n",
        "        \n",
        "        # Find timestep with highest score\n",
        "        best_score = -1\n",
        "        for t_str, data in sens_data.items():\n",
        "            if t_str == \"optimal_window\":\n",
        "                continue\n",
        "            if isinstance(data, dict) and 'score' in data:\n",
        "                score = data['score']\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    best_timestep = int(t_str)\n",
        "        \n",
        "        print(f\"Using best timestep from sensitivity analysis: t={best_timestep} (score={best_score:.3f})\")\n",
        "    else:\n",
        "        print(f\"Using default timestep: t={best_timestep}\")\n",
        "        print(\"  (Run Step 5 to get sensitivity analysis)\")\n",
        "    \n",
        "    if not probe_pytorch.exists():\n",
        "        print(f\"⚠ Error: Probe directory not found: {probe_pytorch}\")\n",
        "    else:\n",
        "        print(f\"\\nVisualizing probe results:\")\n",
        "        print(f\"  Latents: {latest_latents}\")\n",
        "        print(f\"  Probe: {probe_pytorch}\")\n",
        "        print(f\"  Timestep: {best_timestep}\")\n",
        "        \n",
        "        import torch\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        \n",
        "        !python scripts/visualize_probe_results.py \\\n",
        "            --latents_dir {latest_latents} \\\n",
        "            --probe_dir {probe_pytorch} \\\n",
        "            --timestep {best_timestep} \\\n",
        "            --num_samples 30 \\\n",
        "            --device {device}\n",
        "        \n",
        "        # Display visualization\n",
        "        viz_path = Path('outputs/visualizations') / f'probe_visualization_t{best_timestep:02d}.png'\n",
        "        if viz_path.exists():\n",
        "            from IPython.display import Image, display\n",
        "            print(f\"\\n✓ Visualization:\")\n",
        "            display(Image(str(viz_path)))\n",
        "            print(f\"  Saved to: {viz_path}\")\n",
        "        else:\n",
        "            print(\"\\n⚠ Warning: Visualization not found. Check for errors above.\")\n",
        "else:\n",
        "    if not latents_dirs:\n",
        "        print(\"⚠ Error: No latents found! Run Step 4 first.\")\n",
        "    if not probe_dirs:\n",
        "        print(\"⚠ Error: No probes found! Run Step 5 first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Phase 2 - Train PPO Policy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train PPO policy with Colab-optimized config\n",
        "# Colab T4 can handle larger batch sizes than RTX 4050\n",
        "# The config uses probe_path: \"auto\" to automatically find the latest probe\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"PHASE 2: TRAINING PPO POLICY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Verify prerequisites\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "probe_dirs = sorted(Path('checkpoints/probes').glob('run_*'), key=lambda p: p.stat().st_mtime)\n",
        "# Use fast config for 2-3 hour training (reduced from 8 hours)\n",
        "config_file = Path('configs/colab_fast_20steps.yaml')\n",
        "\n",
        "# Fallback to original config if fast config doesn't exist\n",
        "if not config_file.exists():\n",
        "    print(f\"⚠ Fast config not found: {config_file}\")\n",
        "    print(\"  Falling back to colab_optimized.yaml...\")\n",
        "    config_file = Path('configs/colab_optimized.yaml')\n",
        "\n",
        "if not probe_dirs:\n",
        "    print(\"⚠ Error: No probes found! Run Step 5 first.\")\n",
        "elif not config_file.exists():\n",
        "    print(f\"⚠ Error: Config file not found: {config_file}\")\n",
        "else:\n",
        "    latest_probe = probe_dirs[-1]\n",
        "    print(f\"Using probe: {latest_probe}\")\n",
        "    print(f\"Config: {config_file}\")\n",
        "    print(\"\\nTraining settings (FAST MODE - 2-3 hours):\")\n",
        "    print(\"  - Total timesteps: 50,000 (reduced from 200K)\")\n",
        "    print(\"  - Batch size: 32 (Colab T4 optimized)\")\n",
        "    print(\"  - Epochs: 4 (optimal from experiments)\")\n",
        "    print(\"  - Estimated time: 2-3 hours (reduced from 8 hours)\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Check GPU\n",
        "    import torch\n",
        "    if not torch.cuda.is_available():\n",
        "        print(\"⚠ Warning: No GPU detected! Training will be very slow.\")\n",
        "    \n",
        "    print(\"\\nStarting training...\")\n",
        "    !python scripts/train_ppo.py --config {config_file}\n",
        "    \n",
        "    # Check if training completed\n",
        "    ppo_dirs = sorted(Path('outputs/ppo').glob('aether_ppo_*'), key=lambda p: p.stat().st_mtime)\n",
        "    if ppo_dirs:\n",
        "        latest_run = ppo_dirs[-1]\n",
        "        policy_file = latest_run / 'final_policy.pt'\n",
        "        if policy_file.exists():\n",
        "            print(f\"\\n✓ Training complete! Policy saved: {policy_file}\")\n",
        "        else:\n",
        "            print(f\"\\n⚠ Warning: final_policy.pt not found. Check for errors above.\")\n",
        "            print(f\"  Run directory: {latest_run}\")\n",
        "    else:\n",
        "        print(\"\\n⚠ Warning: No training output found. Check for errors above.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Phase 3 - Evaluate Policy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option A: Quick Evaluation\n",
        "\n",
        "Evaluate the trained policy:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate trained policy\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"PHASE 3: EVALUATING POLICY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Find latest policy and probe\n",
        "ppo_dirs = sorted(Path('outputs/ppo').glob('aether_ppo_*'), key=lambda p: p.stat().st_mtime)\n",
        "probe_dirs = sorted(Path('checkpoints/probes').glob('run_*'), key=lambda p: p.stat().st_mtime)\n",
        "\n",
        "if not ppo_dirs:\n",
        "    print(\"⚠ Error: No training runs found! Run Step 7 first.\")\n",
        "elif not probe_dirs:\n",
        "    print(\"⚠ Error: No probe directories found! Run Step 5 first.\")\n",
        "else:\n",
        "    latest_policy = ppo_dirs[-1] / 'final_policy.pt'\n",
        "    latest_probe = probe_dirs[-1] / 'pytorch'\n",
        "    \n",
        "    print(f\"Policy: {latest_policy}\")\n",
        "    print(f\"Probe: {latest_probe}\")\n",
        "    \n",
        "    if not latest_policy.exists():\n",
        "        print(f\"⚠ Error: Policy file not found: {latest_policy}\")\n",
        "        print(f\"  Available files in {ppo_dirs[-1]}:\")\n",
        "        for f in ppo_dirs[-1].glob('*.pt'):\n",
        "            print(f\"    - {f.name}\")\n",
        "    elif not latest_probe.exists():\n",
        "        print(f\"⚠ Error: Probe directory not found: {latest_probe}\")\n",
        "    else:\n",
        "        print(\"\\nEvaluation metrics:\")\n",
        "        print(\"  - SSR (Safety Success Rate): Higher is better\")\n",
        "        print(\"  - FPR (False Positive Rate): Lower is better\")\n",
        "        print(\"  - LPIPS (Perceptual Distance): Lower is better\")\n",
        "        print(\"  - Transport Cost: Lower is better\")\n",
        "        print(\"=\"*60)\n",
        "        \n",
        "        import torch\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        \n",
        "        !python scripts/evaluate_ppo.py \\\n",
        "            --policy_path {latest_policy} \\\n",
        "            --probe_path {latest_probe} \\\n",
        "            --num_samples 50 \\\n",
        "            --device {device}\n",
        "        \n",
        "        # Check for evaluation results\n",
        "        eval_dirs = sorted(Path('outputs/evaluation').glob('eval_*'), key=lambda p: p.stat().st_mtime)\n",
        "        if eval_dirs:\n",
        "            latest_eval = eval_dirs[-1]\n",
        "            print(f\"\\n✓ Evaluation complete! Results: {latest_eval}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option B: Run Multiple Experiments (Compare Hyperparameters)\n",
        "\n",
        "Run different hyperparameter configurations to compare results:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run all experiments (takes ~9-12 hours total)\n",
        "# Each experiment: ~1.5-2 hours, 100K timesteps\n",
        "!python scripts/run_experiments.py --all\n",
        "\n",
        "# Or run specific experiments:\n",
        "# !python scripts/run_experiments.py --experiments exp1 exp2 exp3\n",
        "\n",
        "# Experiments:\n",
        "# exp1: Low lambda (0.3) - aggressive safety\n",
        "# exp2: Medium lambda (0.5) - balanced\n",
        "# exp3: High lambda (0.8) - efficient actions\n",
        "# exp4: Fast learning rate (3e-4)\n",
        "# exp5: More epochs (12)\n",
        "# exp6: Smaller policy (256,128)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Option C: Run Single Experiment Manually\n",
        "\n",
        "Run a specific experiment configuration:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Run experiment 1 (low lambda)\n",
        "!python scripts/train_ppo.py --config configs/colab_experiment_1_low_lambda.yaml\n",
        "\n",
        "# Other experiments:\n",
        "# !python scripts/train_ppo.py --config configs/colab_experiment_2_medium_lambda.yaml\n",
        "# !python scripts/train_ppo.py --config configs/colab_experiment_3_high_lambda.yaml\n",
        "# !python scripts/train_ppo.py --config configs/colab_experiment_4_fast_learning.yaml\n",
        "# !python scripts/train_ppo.py --config configs/colab_experiment_5_more_epochs.yaml\n",
        "# !python scripts/train_ppo.py --config configs/colab_experiment_6_smaller_policy.yaml\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Save Results to Google Drive\n",
        "\n",
        "Mount your Google Drive and save results:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"SAVING RESULTS TO GOOGLE DRIVE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Mount Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copy results to Drive\n",
        "drive_path = Path('/content/drive/MyDrive/project-aether-results')\n",
        "drive_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"\\nCopying results to: {drive_path}\")\n",
        "\n",
        "# Copy outputs\n",
        "if Path('outputs').exists():\n",
        "    print(\"  Copying outputs/...\")\n",
        "    !cp -r outputs {drive_path}/\n",
        "    print(\"    ✓ outputs/\")\n",
        "\n",
        "# Copy checkpoints\n",
        "if Path('checkpoints').exists():\n",
        "    print(\"  Copying checkpoints/...\")\n",
        "    !cp -r checkpoints {drive_path}/\n",
        "    print(\"    ✓ checkpoints/\")\n",
        "\n",
        "# Copy latents\n",
        "if Path('data/latents').exists():\n",
        "    print(\"  Copying data/latents/...\")\n",
        "    !cp -r data/latents {drive_path}/\n",
        "    print(\"    ✓ data/latents/\")\n",
        "\n",
        "# Also copy visualization results if they exist\n",
        "viz_path = Path('outputs/visualizations')\n",
        "if viz_path.exists():\n",
        "    print(\"  Copying visualizations/...\")\n",
        "    !cp -r {viz_path} {drive_path}/outputs/\n",
        "    print(\"    ✓ visualizations/\")\n",
        "\n",
        "print(f\"\\n✓ Results saved to: {drive_path}\")\n",
        "print(f\"\\nSaved directories:\")\n",
        "print(f\"  - Training outputs: {drive_path}/outputs/\")\n",
        "print(f\"  - Probes: {drive_path}/checkpoints/probes/\")\n",
        "print(f\"  - Latents and images: {drive_path}/data/latents/\")\n",
        "if viz_path.exists():\n",
        "    print(f\"  - Visualizations: {drive_path}/outputs/visualizations/\")\n",
        "\n",
        "# Show size\n",
        "import subprocess\n",
        "result = subprocess.run(['du', '-sh', str(drive_path)], capture_output=True, text=True)\n",
        "if result.returncode == 0:\n",
        "    size = result.stdout.split()[0]\n",
        "    print(f\"\\nTotal size: {size}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
