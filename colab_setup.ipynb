{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvfJ6o7cObW3"
      },
      "source": [
        "# Project Aether - Google Colab Setup (A100 Optimized)\n",
        "\n",
        "This notebook sets up and runs Project Aether on Google Colab with GPU support (optimized for A100).\n",
        "\n",
        "## ✨ Phase 1 Improvements\n",
        "\n",
        "**Enhanced Separability Features:**\n",
        "- ✅ **Feature Standardization**: Automatic normalization for better separability (+5-10% accuracy)\n",
        "- ✅ **Hyperparameter Tuning**: Grid search for optimal regularization (+3-7% accuracy)\n",
        "- ✅ **Cross-Validation**: 5-fold CV for reliable metrics (+2-5% accuracy)\n",
        "- ✅ **Enhanced Metrics**: Precision, Recall, F1-score for better diagnostics\n",
        "- ✅ **Float32 Precision**: Better numerical stability\n",
        "- ✅ **Improved Measurement**: Robust empirical layer sensitivity measurement\n",
        "\n",
        "**Expected Results:** ~85-92% probe accuracy (vs ~70-80% before improvements)\n",
        "\n",
        "## Notebook Structure\n",
        "\n",
        "### Phase 0: Setup (Steps 1-3)\n",
        "- Step 1: Install Dependencies\n",
        "- Step 2: Clone Repository or Upload Files\n",
        "- Step 3: Verify GPU and Setup\n",
        "\n",
        "### Phase 1: Probe Training (Steps 4-6)\n",
        "- Step 4: Collect Latents (now uses float32 for better precision)\n",
        "- Step 5: (Optional) Measure Empirical Layer Sensitivity (improved with new options)\n",
        "- Step 6: Train Linear Probes with Improvements (normalization, tuning, CV)\n",
        "- Step 7: Visualize Results\n",
        "\n",
        "### Phase 2: PPO Training (Step 8)\n",
        "- Step 8: Train PPO Policy\n",
        "\n",
        "### Phase 3: Evaluation (Step 9)\n",
        "- Step 9: Evaluate Policy\n",
        "\n",
        "### Save Results (Step 10)\n",
        "- Step 10: Save Results to Google Drive\n",
        "\n",
        "## References\n",
        "- **FID Metric:** Heusel et al. (2017). \"GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium.\" NeurIPS 2017.\n",
        "- **Linear Probing:** Alain & Bengio (2016). \"Understanding Intermediate Layers Using Linear Classifier Probes.\" arXiv:1610.01644.\n",
        "- **PPO:** Schulman et al. (2017). \"Proximal Policy Optimization Algorithms.\" arXiv:1707.06347.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNzvgruwObW4"
      },
      "source": [
        "## Phase 0 Step 1: Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMSiyux1ObW4"
      },
      "outputs": [],
      "source": [
        "# Install PyTorch with CUDA 12.1 (Colab default)\n",
        "print(\"Installing PyTorch...\")\n",
        "!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121 -q\n",
        "\n",
        "# Install other dependencies\n",
        "print(\"Installing core dependencies...\")\n",
        "!pip install diffusers transformers accelerate safetensors -q\n",
        "!pip install gymnasium numpy scikit-learn matplotlib tqdm -q\n",
        "!pip install pyyaml pillow lpips -q\n",
        "!pip install datasets -q  # For I2P dataset\n",
        "!pip install pytorch-fid -q  # For FID metric (Heusel et al., 2017)\n",
        "\n",
        "print(\"✓ All dependencies installed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IddzR5Q0ObW5"
      },
      "source": [
        "## Phase 0 Step 2: Clone Repository or Upload Files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yydHLpsmObW5"
      },
      "outputs": [],
      "source": [
        "# Option A: Clone from GitHub\n",
        "import os\n",
        "if not os.path.exists('project-aether'):\n",
        "    print(\"Cloning repository...\")\n",
        "    !git clone https://github.com/Anastasia-Deniz/project-aether.git\n",
        "    print(\"✓ Repository cloned!\")\n",
        "else:\n",
        "    print(\"✓ Repository already exists, skipping clone\")\n",
        "\n",
        "%cd project-aether\n",
        "\n",
        "# Option B: If you uploaded files manually, uncomment:\n",
        "# %cd /content/project-aether\n",
        "\n",
        "# Verify we're in the right directory\n",
        "import sys\n",
        "from pathlib import Path\n",
        "if Path('scripts/train_ppo.py').exists():\n",
        "    print(f\"✓ Project structure verified! Working directory: {Path.cwd()}\")\n",
        "else:\n",
        "    print(\"⚠ Warning: Project structure not found. Make sure you're in the project-aether directory.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfg7OH_eObW5"
      },
      "source": [
        "## Phase 0 Step 3: Verify GPU and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utZ_Qor6Olx_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Verify GPU\n",
        "print(\"=\"*60)\n",
        "print(\"GPU VERIFICATION\")\n",
        "print(\"=\"*60)\n",
        "cuda_available = torch.cuda.is_available()\n",
        "print(f\"CUDA available: {cuda_available}\")\n",
        "\n",
        "if cuda_available:\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    vram_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f\"GPU: {gpu_name}\")\n",
        "    print(f\"VRAM: {vram_gb:.2f} GB\")\n",
        "\n",
        "    if vram_gb < 12:\n",
        "        print(\"⚠ Warning: Less than 12GB VRAM. Consider reducing batch sizes.\")\n",
        "    else:\n",
        "        print(\"✓ Sufficient VRAM for Colab-optimized config\")\n",
        "else:\n",
        "    print(\"⚠ Warning: No GPU detected! Training will be very slow on CPU.\")\n",
        "    print(\"  Make sure Runtime > Change runtime type > Hardware accelerator = GPU\")\n",
        "\n",
        "# Add project to path\n",
        "project_root = Path.cwd()\n",
        "sys.path.insert(0, str(project_root))\n",
        "print(f\"\\nProject root: {project_root}\")\n",
        "\n",
        "# Create necessary directories\n",
        "print(\"\\nCreating directories...\")\n",
        "dirs = ['data/latents', 'checkpoints/probes', 'outputs/ppo', 'outputs/evaluation', 'outputs/visualizations']\n",
        "for d in dirs:\n",
        "    Path(d).mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"  ✓ {d}\")\n",
        "\n",
        "print(\"\\n✓ Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JJp60tHScWf"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h21BGERYObW6"
      },
      "source": [
        "## Phase 1 Step 4: Collect Latents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fv36-yMJObW6"
      },
      "outputs": [],
      "source": [
        "# Collect latents for probe training\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"PHASE 1: COLLECTING LATENTS\")\n",
        "print(\"=\"*60)\n",
        "print(\"This will:\")\n",
        "print(\"  - Download Stable Diffusion 1.4 model (~4GB)\")\n",
        "print(\"  - Generate 300 safe prompts (diverse categories)\")\n",
        "print(\"  - Generate EXACTLY 300 SEXUAL unsafe prompts (sexual category only)\")\n",
        "print(\"  - Save latents at each timestep\")\n",
        "print(\"=\"*60)\n",
        "print(\"⚠ IMPORTANT: Unsafe prompts are STRICTLY sexual category only\")\n",
        "print(\"   Code will automatically relax criteria if needed to reach 300\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check if CUDA is available\n",
        "import torch\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"⚠ Warning: CUDA not available. This will be very slow!\")\n",
        "    device = \"cpu\"\n",
        "else:\n",
        "    device = \"cuda\"\n",
        "\n",
        "!python scripts/collect_latents.py \\\n",
        "    --num_samples 300 \\\n",
        "    --num_steps 20 \\\n",
        "    --device {device} \\\n",
        "    --model_id CompVis/stable-diffusion-v1-4 \\\n",
        "    --focus_nudity \\\n",
        "    --hard_only \\\n",
        "    --min_inappropriate_pct 60.0 \\\n",
        "    --min_nudity_pct 50.0 \\\n",
        "    --save_images\n",
        "\n",
        "# Verify output and confirm sexual prompt count\n",
        "from pathlib import Path\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "latents_dirs = sorted(Path('data/latents').glob('run_*'), key=lambda p: p.stat().st_mtime)\n",
        "if latents_dirs:\n",
        "    latest = latents_dirs[-1]\n",
        "    print(f\"\\n✓ Latents collected! Output: {latest}\")\n",
        "\n",
        "    # Count files\n",
        "    latent_files = list(latest.glob('latents/timestep_*.npz'))\n",
        "    print(f\"  Found {len(latent_files)} timestep files\")\n",
        "\n",
        "    # Verify prompt counts\n",
        "    safe_prompts_file = latest / \"safe_prompts.json\"\n",
        "    unsafe_prompts_file = latest / \"unsafe_prompts.json\"\n",
        "\n",
        "    if safe_prompts_file.exists():\n",
        "        with open(safe_prompts_file) as f:\n",
        "            safe_prompts = json.load(f)\n",
        "        print(f\"  ✓ Safe prompts: {len(safe_prompts)}\")\n",
        "\n",
        "    if unsafe_prompts_file.exists():\n",
        "        with open(unsafe_prompts_file) as f:\n",
        "            unsafe_prompts = json.load(f)\n",
        "\n",
        "        # Count sexual-only prompts\n",
        "        sexual_count = sum(1 for p in unsafe_prompts if \"sexual\" in p.get(\"categories\", \"\").lower())\n",
        "        print(f\"  ✓ Unsafe prompts: {len(unsafe_prompts)}\")\n",
        "        print(f\"  ✓ Sexual category prompts: {sexual_count}\")\n",
        "\n",
        "        if sexual_count < 300:\n",
        "            print(f\"\\n⚠ Warning: Only {sexual_count} sexual prompts found (requested 300)\")\n",
        "            print(\"   This may be due to:\")\n",
        "            print(\"   - Dataset limitations\")\n",
        "            print(\"   - Strict filtering criteria\")\n",
        "            print(\"   - CLIP token length limits\")\n",
        "        elif sexual_count == 300:\n",
        "            print(f\"\\n✓ Perfect! Exactly {sexual_count} sexual prompts collected\")\n",
        "        else:\n",
        "            print(f\"\\n✓ Found {sexual_count} sexual prompts (target was 300)\")\n",
        "\n",
        "    # Verify latent data\n",
        "    if latent_files:\n",
        "        sample_file = latent_files[0]\n",
        "        data = np.load(sample_file)\n",
        "        labels = data['y']\n",
        "        safe_count = np.sum(labels == 0)\n",
        "        unsafe_count = np.sum(labels == 1)\n",
        "        print(f\"\\n  Label distribution in latents:\")\n",
        "        print(f\"    Safe (0): {safe_count}\")\n",
        "        print(f\"    Unsafe (1): {unsafe_count}\")\n",
        "        print(f\"    Total: {len(labels)}\")\n",
        "else:\n",
        "    print(\"\\n⚠ Warning: No latents directory found. Check for errors above.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1GKFMr2ObW5"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJO0O4NHObW5"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMMXJ76vObW6"
      },
      "source": [
        "## Phase 1 Step 5: (Optional) Measure Empirical Layer Sensitivity ⭐\n",
        "\n",
        "**Recommended for best results:** Measure FID and SSR empirically instead of using heuristics.\n",
        "\n",
        "This step runs small steering experiments to measure:\n",
        "- **Quality preservation**: FID between steered and unsteered images (1 - FID_norm)\n",
        "- **Steering effectiveness**: SSR improvement from steering at each timestep\n",
        "\n",
        "**Improvements:**\n",
        "- ✅ Automatic scaler loading (if available from probe training)\n",
        "- ✅ Flexible sampling options (`--sample_timesteps` for faster measurement)\n",
        "- ✅ Robust error handling with fallbacks\n",
        "- ✅ Better progress reporting and time estimation\n",
        "- ✅ LPIPS fallback if pytorch-fid unavailable\n",
        "\n",
        "**Note:** This takes ~30-60 minutes but provides more accurate sensitivity scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3RPCWMDObW6"
      },
      "outputs": [],
      "source": [
        "# Measure empirical layer sensitivity (FID and SSR)\n",
        "# This improves the quality of layer sensitivity analysis\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"MEASURING EMPIRICAL LAYER SENSITIVITY\")\n",
        "print(\"=\"*60)\n",
        "print(\"This step:\")\n",
        "print(\"  - Runs small steering experiments at each timestep\")\n",
        "print(\"  - Measures FID (quality preservation)\")\n",
        "print(\"  - Measures SSR (steering effectiveness)\")\n",
        "print(\"  - Estimated time: 30-60 minutes\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "latents_dirs = sorted(Path('data/latents').glob('run_*'), key=lambda p: p.stat().st_mtime)\n",
        "probe_dirs = sorted(Path('checkpoints/probes').glob('run_*'), key=lambda p: p.stat().st_mtime)\n",
        "\n",
        "if latents_dirs:\n",
        "    latest_latents = latents_dirs[-1]\n",
        "    print(f\"\\nUsing latents from: {latest_latents}\")\n",
        "\n",
        "    # Use probe from Step 5 if available\n",
        "    probe_path = None\n",
        "    if probe_dirs:\n",
        "        latest_probe = probe_dirs[-1] / 'pytorch'\n",
        "        if latest_probe.exists():\n",
        "            probe_path = str(latest_probe)\n",
        "            print(f\"Using probe: {probe_path}\")\n",
        "        else:\n",
        "            print(\"⚠ Warning: Probe directory exists but pytorch/ subdirectory not found\")\n",
        "    else:\n",
        "        print(\"⚠ Warning: No probes found. Running without probe (will use random steering)\")\n",
        "\n",
        "    # Check if already measured\n",
        "    quality_file = latest_latents / \"quality_measurements.json\"\n",
        "    effectiveness_file = latest_latents / \"effectiveness_measurements.json\"\n",
        "\n",
        "    if quality_file.exists() and effectiveness_file.exists():\n",
        "        print(\"\\n✓ Measurements already exist! Skipping measurement.\")\n",
        "        print(f\"  Quality: {quality_file}\")\n",
        "        print(f\"  Effectiveness: {effectiveness_file}\")\n",
        "        print(\"\\nTo re-measure, delete these files first.\")\n",
        "    else:\n",
        "        print(f\"\\nMeasuring empirical sensitivity...\")\n",
        "        print(\"This may take 30-60 minutes...\")\n",
        "\n",
        "        import torch\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "        # For faster measurement, use --sample_timesteps (e.g., 5 timesteps)\n",
        "        # For full accuracy, remove --sample_timesteps to measure all timesteps\n",
        "        if probe_path:\n",
        "            !python scripts/measure_layer_sensitivity.py \\\n",
        "                --latents_dir {latest_latents} \\\n",
        "                --num_samples 20 \\\n",
        "                --device {device} \\\n",
        "                --probe_path {probe_path} \\\n",
        "                --sample_timesteps 5\n",
        "        else:\n",
        "            !python scripts/measure_layer_sensitivity.py \\\n",
        "                --latents_dir {latest_latents} \\\n",
        "                --num_samples 20 \\\n",
        "                --device {device} \\\n",
        "                --sample_timesteps 5\n",
        "\n",
        "        # Verify measurements were created\n",
        "        quality_file = latest_latents / \"quality_measurements.json\"\n",
        "        effectiveness_file = latest_latents / \"effectiveness_measurements.json\"\n",
        "\n",
        "        if quality_file.exists():\n",
        "            print(f\"\\n✓ Quality measurements saved: {quality_file}\")\n",
        "        else:\n",
        "            print(f\"\\n⚠ Warning: Quality measurements not found\")\n",
        "\n",
        "        if effectiveness_file.exists():\n",
        "            print(f\"✓ Effectiveness measurements saved: {effectiveness_file}\")\n",
        "        else:\n",
        "            print(f\"⚠ Warning: Effectiveness measurements not found\")\n",
        "\n",
        "        if quality_file.exists():\n",
        "            if effectiveness_file.exists():\n",
        "                print(\"\\n✓ Complete measurements saved! Both quality and effectiveness available.\")\n",
        "                print(\"  Now proceed to Step 6 to train probes with --use_empirical\")\n",
        "            else:\n",
        "                print(\"\\n✓ Quality measurements saved!\")\n",
        "                print(\"  ⚠ Note: Effectiveness measurements not available (requires trained probe).\")\n",
        "                print(\"  This is normal if you ran Step 5 before Step 6.\")\n",
        "                print(\"  You can:\")\n",
        "                print(\"    1. Proceed to Step 6 to train probes\")\n",
        "                print(\"    2. Re-run Step 5 after Step 6 to get effectiveness measurements\")\n",
        "        else:\n",
        "            print(\"\\n⚠ Warning: Quality measurements not found. Check for errors above.\")\n",
        "else:\n",
        "    print(\"⚠ Error: No latents found! Run Step 4 first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofDSxAc-ObW6"
      },
      "source": [
        "## Phase 1 Step 6: Train Linear Probes with Improvements ⭐\n",
        "\n",
        "**Enhanced Training Features:**\n",
        "- ✅ **Feature Standardization**: Automatic normalization (enabled by default)\n",
        "- ✅ **Hyperparameter Tuning**: Grid search for optimal C (use `--tune_hyperparams`)\n",
        "- ✅ **Cross-Validation**: 5-fold CV for reliable metrics (use `--use_cv`)\n",
        "- ✅ **Enhanced Metrics**: Precision, Recall, F1-score\n",
        "\n",
        "**Expected Results:** ~85-92% accuracy (vs ~70-80% without improvements)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kd2oQueRObW6"
      },
      "outputs": [],
      "source": [
        "# Train linear probes\n",
        "# Find the latest latents directory\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"PHASE 1: TRAINING LINEAR PROBES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "latents_dirs = sorted(Path('data/latents').glob('run_*'), key=lambda p: p.stat().st_mtime)\n",
        "if latents_dirs:\n",
        "    latest_latents = latents_dirs[-1]\n",
        "    print(f\"Using latents from: {latest_latents}\")\n",
        "\n",
        "    # Check if empirical measurements exist\n",
        "    use_empirical = False\n",
        "    quality_file = latest_latents / \"quality_measurements.json\"\n",
        "    effectiveness_file = latest_latents / \"effectiveness_measurements.json\"\n",
        "\n",
        "    if quality_file.exists() and effectiveness_file.exists():\n",
        "        print(\"✓ Found complete empirical measurements! Using them for better accuracy.\")\n",
        "        use_empirical = True\n",
        "    elif quality_file.exists():\n",
        "        print(\"✓ Found quality measurements (effectiveness measurements missing).\")\n",
        "        print(\"  Note: Effectiveness measurements require a trained probe.\")\n",
        "        print(\"  You can proceed with training - quality measurements will be used.\")\n",
        "        use_empirical = True  # Can still use quality measurements\n",
        "    else:\n",
        "        print(\"Using improved heuristics (faster). For better accuracy, run Step 5 first.\")\n",
        "\n",
        "    # Train probes with improvements\n",
        "    # Options:\n",
        "    #   --tune_hyperparams: Grid search for optimal C (slower but better)\n",
        "    #   --use_cv: 5-fold cross-validation (slower but more reliable)\n",
        "    #   --normalize_features: Feature standardization (enabled by default)\n",
        "    #   --use_empirical: Use empirical measurements if available\n",
        "    \n",
        "    print(\"\\nTraining with improvements:\")\n",
        "    print(\"  ✓ Feature normalization (automatic)\")\n",
        "    print(\"  ✓ Hyperparameter tuning (--tune_hyperparams)\")\n",
        "    print(\"  ✓ Cross-validation (--use_cv)\")\n",
        "    \n",
        "    import os\n",
        "    \n",
        "    # Build command\n",
        "    cmd_parts = [\"python\", \"scripts/train_probes.py\", \"--latents_dir\", str(latest_latents)]\n",
        "    \n",
        "    # Add improvement flags\n",
        "    cmd_parts.extend([\"--tune_hyperparams\", \"--use_cv\"])\n",
        "    \n",
        "    # Add empirical flag if measurements exist\n",
        "    if use_empirical:\n",
        "        cmd_parts.append(\"--use_empirical\")\n",
        "        print(\"  ✓ Using empirical measurements\")\n",
        "    \n",
        "    cmd = \" \".join(cmd_parts)\n",
        "    print(f\"\\nCommand: {cmd}\\n\")\n",
        "    os.system(cmd)\n",
        "\n",
        "    # Print probe results summary\n",
        "    probe_dirs = sorted(Path('checkpoints/probes').glob('run_*'), key=lambda p: p.stat().st_mtime)\n",
        "    if probe_dirs:\n",
        "        latest_probe = probe_dirs[-1]\n",
        "        metrics_file = latest_probe / 'probe_metrics.json'\n",
        "        sensitivity_file = latest_probe / 'sensitivity_scores.json'\n",
        "\n",
        "        if metrics_file.exists():\n",
        "            with open(metrics_file) as f:\n",
        "                metrics = json.load(f)\n",
        "\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"PROBE ACCURACY SUMMARY\")\n",
        "            print(\"=\"*60)\n",
        "            best_acc = 0\n",
        "            best_t = None\n",
        "            for t in sorted(metrics.keys(), key=int):\n",
        "                acc = metrics[t]['test_acc']\n",
        "                t_int = int(t)  # Convert string key to int for formatting\n",
        "                print(f\"Timestep {t_int:2d}: {acc:.3f} ({acc*100:5.1f}%)\")\n",
        "                if acc > best_acc:\n",
        "                    best_acc = acc\n",
        "                    best_t = t_int\n",
        "\n",
        "            print(f\"\\n✓ Best accuracy: {best_acc:.3f} at timestep {best_t}\")\n",
        "            \n",
        "            # Check if accuracy meets threshold\n",
        "            if best_acc > 0.85:\n",
        "                print(\"  ✅ EXCELLENT: Linear separability confirmed! (>85%)\")\n",
        "            elif best_acc > 0.70:\n",
        "                print(\"  ⚠ MODERATE: Partial separability (70-85%)\")\n",
        "                print(\"    Consider: More samples, better prompts, or MLP probe\")\n",
        "            else:\n",
        "                print(\"  ⚠ LOW: Poor separability (<70%)\")\n",
        "                print(\"    Consider: Review data quality, try MLP probe\")\n",
        "\n",
        "            # Check sensitivity scores\n",
        "            if sensitivity_file.exists():\n",
        "                with open(sensitivity_file) as f:\n",
        "                    sens_data = json.load(f)\n",
        "\n",
        "                if 'optimal_window' in sens_data:\n",
        "                    window = sens_data['optimal_window']\n",
        "                    print(f\"\\n✓ Recommended intervention window: steps {window.get('start', '?')} to {window.get('end', '?')}\")\n",
        "                    if 'top_timesteps' in window:\n",
        "                        print(f\"  Top timesteps: {window['top_timesteps']}\")\n",
        "                    \n",
        "                    # Show if empirical measurements were used\n",
        "                    if use_empirical:\n",
        "                        print(\"  (Using empirical measurements for better accuracy)\")\n",
        "                    else:\n",
        "                        print(\"  (Using heuristics - run Step 5 for empirical measurements)\")\n",
        "        else:\n",
        "            print(\"⚠ Warning: probe_metrics.json not found\")\n",
        "    else:\n",
        "        print(\"⚠ Warning: No probe directories created. Check for errors above.\")\n",
        "else:\n",
        "    print(\"⚠ Error: No latents found! Run Step 4 first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ms6q28sObW7"
      },
      "source": [
        "## Phase 1 Step 7: Visualize Generated Images & Verify Probe Accuracy\n",
        "**Important:** Before training PPO, verify that the generated images match their labels!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-u4oC4mXObW7"
      },
      "outputs": [],
      "source": [
        "# Generate images from collected latents to verify what was actually generated\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"GENERATING IMAGES FROM LATENTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "latents_dirs = sorted(Path('data/latents').glob('run_*'), key=lambda p: p.stat().st_mtime)\n",
        "if latents_dirs:\n",
        "    latest_latents = latents_dirs[-1]\n",
        "    print(f\"Using latents from: {latest_latents}\")\n",
        "\n",
        "    # Check if images already exist\n",
        "    viewer_path = latest_latents / \"images_t20/viewer.html\"\n",
        "    if viewer_path.exists():\n",
        "        print(\"\\n✓ Images already generated! Skipping...\")\n",
        "        print(f\"  Viewer: {viewer_path}\")\n",
        "    else:\n",
        "        print(\"\\nGenerating images from final timestep (t=20)...\")\n",
        "        print(\"This may take 5-10 minutes...\")\n",
        "\n",
        "        import torch\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "        !python scripts/generate_images_from_latents.py \\\n",
        "            --latents_dir {latest_latents} \\\n",
        "            --timestep 20 \\\n",
        "            --num_samples 50 \\\n",
        "            --device {device}\n",
        "\n",
        "        # Check if HTML viewer was created\n",
        "        viewer_path = latest_latents / \"images_t20/viewer.html\"\n",
        "        if viewer_path.exists():\n",
        "            print(f\"\\n✓ Images generated! Viewer: {viewer_path}\")\n",
        "        else:\n",
        "            print(\"\\n⚠ Warning: HTML viewer not found. Check for errors above.\")\n",
        "\n",
        "    # Show how to view\n",
        "    if viewer_path.exists():\n",
        "        print(\"\\nTo view images in Colab, run the next cell!\")\n",
        "else:\n",
        "    print(\"⚠ Error: No latents found! Run Step 4 first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDyebLaBObW7"
      },
      "source": [
        "### View Images in Colab\n",
        "\n",
        "Display the HTML viewer directly in the notebook:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvbGb0nLObW7"
      },
      "outputs": [],
      "source": [
        "# Display HTML viewer in Colab\n",
        "from IPython.display import HTML, display\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "latents_dirs = sorted(Path('data/latents').glob('run_*'), key=os.path.getmtime)\n",
        "if latents_dirs:\n",
        "    latest_latents = latents_dirs[-1]\n",
        "    viewer_path = latest_latents / \"images_t20/viewer.html\"\n",
        "\n",
        "    if viewer_path.exists():\n",
        "        with open(viewer_path, 'r', encoding='utf-8') as f:\n",
        "            html_content = f.read()\n",
        "        display(HTML(html_content))\n",
        "    else:\n",
        "        print(\"Viewer not found. Run the previous cell first.\")\n",
        "else:\n",
        "    print(\"No latents found!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZakwWBYLObW7"
      },
      "source": [
        "### Visualize Probe Results\n",
        "\n",
        "See which images are correctly/incorrectly classified by the probe:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzUaCJwpObW7"
      },
      "outputs": [],
      "source": [
        "# Visualize probe predictions on images\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"VISUALIZING PROBE RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "latents_dirs = sorted(Path('data/latents').glob('run_*'), key=lambda p: p.stat().st_mtime)\n",
        "probe_dirs = sorted(Path('checkpoints/probes').glob('run_*'), key=lambda p: p.stat().st_mtime)\n",
        "\n",
        "if latents_dirs and probe_dirs:\n",
        "    latest_latents = latents_dirs[-1]\n",
        "    latest_probe = probe_dirs[-1]\n",
        "    probe_pytorch = latest_probe / 'pytorch'\n",
        "\n",
        "    # Find best timestep from sensitivity analysis\n",
        "    best_timestep = 4  # Default\n",
        "    sensitivity_file = latest_probe / 'sensitivity_scores.json'\n",
        "\n",
        "    if sensitivity_file.exists():\n",
        "        with open(sensitivity_file) as f:\n",
        "            sens_data = json.load(f)\n",
        "\n",
        "        # Find timestep with highest score\n",
        "        best_score = -1\n",
        "        for t_str, data in sens_data.items():\n",
        "            if t_str == \"optimal_window\":\n",
        "                continue\n",
        "            if isinstance(data, dict) and 'score' in data:\n",
        "                score = data['score']\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    best_timestep = int(t_str)\n",
        "\n",
        "        print(f\"Using best timestep from sensitivity analysis: t={best_timestep} (score={best_score:.3f})\")\n",
        "    else:\n",
        "        print(f\"Using default timestep: t={best_timestep}\")\n",
        "        print(\"  (Run Step 5 to get sensitivity analysis)\")\n",
        "\n",
        "    if not probe_pytorch.exists():\n",
        "        print(f\"⚠ Error: Probe directory not found: {probe_pytorch}\")\n",
        "    else:\n",
        "        print(f\"\\nVisualizing probe results:\")\n",
        "        print(f\"  Latents: {latest_latents}\")\n",
        "        print(f\"  Probe: {probe_pytorch}\")\n",
        "        print(f\"  Timestep: {best_timestep}\")\n",
        "\n",
        "        import torch\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "        !python scripts/visualize_probe_results.py \\\n",
        "            --latents_dir {latest_latents} \\\n",
        "            --probe_dir {probe_pytorch} \\\n",
        "            --timestep {best_timestep} \\\n",
        "            --num_samples 30 \\\n",
        "            --device {device}\n",
        "\n",
        "        # Display visualization\n",
        "        viz_path = Path('outputs/visualizations') / f'probe_visualization_t{best_timestep:02d}.png'\n",
        "        if viz_path.exists():\n",
        "            from IPython.display import Image, display\n",
        "            print(f\"\\n✓ Visualization:\")\n",
        "            display(Image(str(viz_path)))\n",
        "            print(f\"  Saved to: {viz_path}\")\n",
        "        else:\n",
        "            print(\"\\n⚠ Warning: Visualization not found. Check for errors above.\")\n",
        "else:\n",
        "    if not latents_dirs:\n",
        "        print(\"⚠ Error: No latents found! Run Step 4 first.\")\n",
        "    if not probe_dirs:\n",
        "        print(\"⚠ Error: No probes found! Run Step 5 first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQuIrHrIObW8"
      },
      "source": [
        "## Phase 2 Step 7:Train PPO Policy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKENhDdBObW8"
      },
      "outputs": [],
      "source": [
        "# Train PPO policy with Colab-optimized config\n",
        "# Auto-detects GPU type (A100 vs T4) and uses appropriate config\n",
        "# The config uses probe_path: \"auto\" to automatically find the latest probe\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"PHASE 2: TRAINING PPO POLICY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Verify prerequisites\n",
        "from pathlib import Path\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# Detect GPU type and select appropriate config\n",
        "gpu_name = \"\"\n",
        "vram_gb = 0\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    vram_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f\"GPU detected: {gpu_name}\")\n",
        "    print(f\"VRAM: {vram_gb:.1f} GB\")\n",
        "else:\n",
        "    print(\"⚠ Warning: No GPU detected! Training will be very slow.\")\n",
        "\n",
        "probe_dirs = sorted(Path('checkpoints/probes').glob('run_*'), key=lambda p: p.stat().st_mtime)\n",
        "\n",
        "# Select config based on GPU\n",
        "if \"A100\" in gpu_name or (torch.cuda.is_available() and vram_gb >= 35):\n",
        "    # A100 detected - use A100 optimized config\n",
        "    print(\"\\n✓ A100 GPU detected! Using A100-optimized config\")\n",
        "    print(\"  Available configs:\")\n",
        "    print(\"    - colab_a100_fast.yaml (1-2 hours, quick experiments)\")\n",
        "    print(\"    - colab_a100_optimized.yaml (2-3 hours, recommended)\")\n",
        "    print(\"    - colab_a100_best.yaml (3-4 hours, maximum quality)\")\n",
        "\n",
        "    # Default to optimized, but user can change\n",
        "    config_file = Path('configs/colab_a100_optimized.yaml')\n",
        "\n",
        "    # Check if user wants fast or best mode (can be changed)\n",
        "    use_fast = False  # Set to True for faster training\n",
        "    use_best = False  # Set to True for best quality\n",
        "\n",
        "    if use_fast:\n",
        "        config_file = Path('configs/colab_a100_fast.yaml')\n",
        "        print(\"  → Using FAST config (1-2 hours)\")\n",
        "    elif use_best:\n",
        "        config_file = Path('configs/colab_a100_best.yaml')\n",
        "        print(\"  → Using BEST config (3-4 hours, maximum quality)\")\n",
        "    else:\n",
        "        print(\"  → Using OPTIMIZED config (2-3 hours, recommended)\")\n",
        "\n",
        "    # Fallback chain for A100\n",
        "    if not config_file.exists():\n",
        "        print(f\"⚠ Config not found: {config_file}\")\n",
        "        if Path('configs/colab_a100_fast.yaml').exists():\n",
        "            config_file = Path('configs/colab_a100_fast.yaml')\n",
        "            print(\"  Falling back to colab_a100_fast.yaml...\")\n",
        "        elif Path('configs/colab_optimized.yaml').exists():\n",
        "            config_file = Path('configs/colab_optimized.yaml')\n",
        "            print(\"  Falling back to colab_optimized.yaml...\")\n",
        "else:\n",
        "    # T4 or other GPU - use T4 config\n",
        "    print(\"\\n✓ T4 or other GPU detected. Using T4-optimized config\")\n",
        "    config_file = Path('configs/colab_fast_20steps.yaml')\n",
        "\n",
        "    # Fallback to original config if fast config doesn't exist\n",
        "    if not config_file.exists():\n",
        "        print(f\"⚠ Fast config not found: {config_file}\")\n",
        "        print(\"  Falling back to colab_optimized.yaml...\")\n",
        "        config_file = Path('configs/colab_optimized.yaml')\n",
        "\n",
        "if not probe_dirs:\n",
        "    print(\"⚠ Error: No probes found! Run Step 5 first.\")\n",
        "elif not config_file.exists():\n",
        "    print(f\"⚠ Error: Config file not found: {config_file}\")\n",
        "else:\n",
        "    latest_probe = probe_dirs[-1]\n",
        "    print(f\"Using probe: {latest_probe}\")\n",
        "    print(f\"Config: {config_file}\")\n",
        "\n",
        "    # Print training settings based on config\n",
        "    if \"a100\" in str(config_file).lower():\n",
        "        if \"fast\" in str(config_file).lower():\n",
        "            print(\"\\nTraining settings (A100 FAST MODE - 1-2 hours):\")\n",
        "            print(\"  - Total timesteps: 50,000\")\n",
        "            print(\"  - Batch size: 128 (A100 optimized)\")\n",
        "            print(\"  - Rollout size: 256\")\n",
        "            print(\"  - Epochs: 4\")\n",
        "            print(\"  - Estimated time: 1-2 hours\")\n",
        "        elif \"best\" in str(config_file).lower():\n",
        "            print(\"\\nTraining settings (A100 BEST MODE - 3-4 hours):\")\n",
        "            print(\"  - Total timesteps: 200,000\")\n",
        "            print(\"  - Batch size: 128 (A100 optimized)\")\n",
        "            print(\"  - Rollout size: 512\")\n",
        "            print(\"  - Epochs: 8\")\n",
        "            print(\"  - Policy: [1024, 512, 256] (largest)\")\n",
        "            print(\"  - Estimated time: 3-4 hours\")\n",
        "        else:\n",
        "            print(\"\\nTraining settings (A100 OPTIMIZED MODE - 2-3 hours):\")\n",
        "            print(\"  - Total timesteps: 100,000\")\n",
        "            print(\"  - Batch size: 128 (A100 optimized)\")\n",
        "            print(\"  - Rollout size: 256\")\n",
        "            print(\"  - Epochs: 6\")\n",
        "            print(\"  - Policy: [1024, 512, 256]\")\n",
        "            print(\"  - Estimated time: 2-3 hours\")\n",
        "    else:\n",
        "        print(\"\\nTraining settings (T4 FAST MODE - 2-3 hours):\")\n",
        "        print(\"  - Total timesteps: 50,000\")\n",
        "        print(\"  - Batch size: 32 (T4 optimized)\")\n",
        "        print(\"  - Epochs: 4\")\n",
        "        print(\"  - Estimated time: 2-3 hours\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    if not torch.cuda.is_available():\n",
        "        print(\"⚠ Warning: No GPU detected! Training will be very slow.\")\n",
        "\n",
        "    print(\"\\nStarting training...\")\n",
        "    !python scripts/train_ppo.py --config {config_file}\n",
        "\n",
        "    # Check if training completed\n",
        "    ppo_dirs = sorted(Path('outputs/ppo').glob('aether_ppo_*'), key=lambda p: p.stat().st_mtime)\n",
        "    if ppo_dirs:\n",
        "        latest_run = ppo_dirs[-1]\n",
        "        policy_file = latest_run / 'final_policy.pt'\n",
        "        if policy_file.exists():\n",
        "            print(f\"\\n✓ Training complete! Policy saved: {policy_file}\")\n",
        "        else:\n",
        "            print(f\"\\n⚠ Warning: final_policy.pt not found. Check for errors above.\")\n",
        "            print(f\"  Run directory: {latest_run}\")\n",
        "    else:\n",
        "        print(\"\\n⚠ Warning: No training output found. Check for errors above.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDZUY13OObW8"
      },
      "source": [
        "## Phase 3 Step 8: Evaluate Policy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDBZMBwTObW8"
      },
      "source": [
        "### Option A: Quick Evaluation\n",
        "\n",
        "Evaluate the trained policy:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zao1CwkSObW8"
      },
      "outputs": [],
      "source": [
        "# Evaluate trained policy\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"PHASE 3: EVALUATING POLICY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Find latest policy and probe\n",
        "ppo_dirs = sorted(Path('outputs/ppo').glob('aether_ppo_*'), key=lambda p: p.stat().st_mtime)\n",
        "probe_dirs = sorted(Path('checkpoints/probes').glob('run_*'), key=lambda p: p.stat().st_mtime)\n",
        "\n",
        "if not ppo_dirs:\n",
        "    print(\"⚠ Error: No training runs found! Run Step 7 first.\")\n",
        "elif not probe_dirs:\n",
        "    print(\"⚠ Error: No probe directories found! Run Step 5 first.\")\n",
        "else:\n",
        "    latest_policy = ppo_dirs[-1] / 'final_policy.pt'\n",
        "    latest_probe = probe_dirs[-1] / 'pytorch'\n",
        "\n",
        "    print(f\"Policy: {latest_policy}\")\n",
        "    print(f\"Probe: {latest_probe}\")\n",
        "\n",
        "    if not latest_policy.exists():\n",
        "        print(f\"⚠ Error: Policy file not found: {latest_policy}\")\n",
        "        print(f\"  Available files in {ppo_dirs[-1]}:\")\n",
        "        for f in ppo_dirs[-1].glob('*.pt'):\n",
        "            print(f\"    - {f.name}\")\n",
        "    elif not latest_probe.exists():\n",
        "        print(f\"⚠ Error: Probe directory not found: {latest_probe}\")\n",
        "    else:\n",
        "        print(\"\\nEvaluation metrics:\")\n",
        "        print(\"  - SSR (Safety Success Rate): Higher is better\")\n",
        "        print(\"  - FPR (False Positive Rate): Lower is better\")\n",
        "        print(\"  - LPIPS (Perceptual Distance): Lower is better\")\n",
        "        print(\"  - Transport Cost: Lower is better\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        import torch\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "        !python scripts/evaluate_ppo.py \\\n",
        "            --policy_path {latest_policy} \\\n",
        "            --probe_path {latest_probe} \\\n",
        "            --num_samples 50 \\\n",
        "            --device {device}\n",
        "\n",
        "        # Check for evaluation results\n",
        "        eval_dirs = sorted(Path('outputs/evaluation').glob('eval_*'), key=lambda p: p.stat().st_mtime)\n",
        "        if eval_dirs:\n",
        "            latest_eval = eval_dirs[-1]\n",
        "            print(f\"\\n✓ Evaluation complete! Results: {latest_eval}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsumpVWGObW8"
      },
      "source": [
        "### Option B: Run Multiple Experiments (Compare Hyperparameters)\n",
        "\n",
        "Run different hyperparameter configurations to compare results:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiihnmxVObW8"
      },
      "outputs": [],
      "source": [
        "# Run all experiments (takes ~9-12 hours total)\n",
        "# Each experiment: ~1.5-2 hours, 100K timesteps\n",
        "!python scripts/run_experiments.py --all\n",
        "\n",
        "# Or run specific experiments:\n",
        "# !python scripts/run_experiments.py --experiments exp1 exp2 exp3\n",
        "\n",
        "# Experiments:\n",
        "# exp1: Low lambda (0.3) - aggressive safety\n",
        "# exp2: Medium lambda (0.5) - balanced\n",
        "# exp3: High lambda (0.8) - efficient actions\n",
        "# exp4: Fast learning rate (3e-4)\n",
        "# exp5: More epochs (12)\n",
        "# exp6: Smaller policy (256,128)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJRTFfqEObW8"
      },
      "outputs": [],
      "source": [
        "### Option C: Run Single Experiment Manually\n",
        "\n",
        "Run a specific experiment configuration:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44wr39IqObW9"
      },
      "outputs": [],
      "source": [
        "# Example: Run experiment 1 (low lambda)\n",
        "!python scripts/train_ppo.py --config configs/colab_experiment_1_low_lambda.yaml\n",
        "\n",
        "# Other experiments:\n",
        "# !python scripts/train_ppo.py --config configs/colab_experiment_2_medium_lambda.yaml\n",
        "# !python scripts/train_ppo.py --config configs/colab_experiment_3_high_lambda.yaml\n",
        "# !python scripts/train_ppo.py --config configs/colab_experiment_4_fast_learning.yaml\n",
        "# !python scripts/train_ppo.py --config configs/colab_experiment_5_more_epochs.yaml\n",
        "# !python scripts/train_ppo.py --config configs/colab_experiment_6_smaller_policy.yaml\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txK3njJ-ObW9"
      },
      "source": [
        "## Phase 3 Step 9: Save Results to Google Drive\n",
        "\n",
        "Mount your Google Drive and save results:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYHGJ5jiObW9"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"SAVING RESULTS TO GOOGLE DRIVE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Mount Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copy results to Drive\n",
        "drive_path = Path('/content/drive/MyDrive/project-aether-results')\n",
        "drive_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"\\nCopying results to: {drive_path}\")\n",
        "\n",
        "# Copy outputs\n",
        "if Path('outputs').exists():\n",
        "    print(\"  Copying outputs/...\")\n",
        "    !cp -r outputs {drive_path}/\n",
        "    print(\"    ✓ outputs/\")\n",
        "\n",
        "# Copy checkpoints\n",
        "if Path('checkpoints').exists():\n",
        "    print(\"  Copying checkpoints/...\")\n",
        "    !cp -r checkpoints {drive_path}/\n",
        "    print(\"    ✓ checkpoints/\")\n",
        "\n",
        "# Copy latents\n",
        "if Path('data/latents').exists():\n",
        "    print(\"  Copying data/latents/...\")\n",
        "    !cp -r data/latents {drive_path}/\n",
        "    print(\"    ✓ data/latents/\")\n",
        "\n",
        "# Also copy visualization results if they exist\n",
        "viz_path = Path('outputs/visualizations')\n",
        "if viz_path.exists():\n",
        "    print(\"  Copying visualizations/...\")\n",
        "    !cp -r {viz_path} {drive_path}/outputs/\n",
        "    print(\"    ✓ visualizations/\")\n",
        "\n",
        "print(f\"\\n✓ Results saved to: {drive_path}\")\n",
        "print(f\"\\nSaved directories:\")\n",
        "print(f\"  - Training outputs: {drive_path}/outputs/\")\n",
        "print(f\"  - Probes: {drive_path}/checkpoints/probes/\")\n",
        "print(f\"  - Latents and images: {drive_path}/data/latents/\")\n",
        "if viz_path.exists():\n",
        "    print(f\"  - Visualizations: {drive_path}/outputs/visualizations/\")\n",
        "\n",
        "# Show size\n",
        "import subprocess\n",
        "result = subprocess.run(['du', '-sh', str(drive_path)], capture_output=True, text=True)\n",
        "if result.returncode == 0:\n",
        "    size = result.stdout.split()[0]\n",
        "    print(f\"\\nTotal size: {size}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
