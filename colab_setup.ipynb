{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Project Aether - Google Colab Setup\n",
        "\n",
        "This notebook sets up and runs Project Aether on Google Colab with GPU support.\n",
        "\n",
        "## Features\n",
        "- Automatic GPU detection and setup\n",
        "- Model downloads (LCM Stable Diffusion)\n",
        "- All three phases: Probe Training, PPO Training, Evaluation\n",
        "- Optimized for Colab's T4 GPU (16GB VRAM)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install PyTorch with CUDA 12.1 (Colab default)\n",
        "!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# Install other dependencies\n",
        "!pip install diffusers transformers accelerate safetensors\n",
        "!pip install gymnasium numpy scikit-learn matplotlib tqdm\n",
        "!pip install pyyaml pillow lpips\n",
        "!pip install datasets  # For I2P dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Clone Repository or Upload Files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option A: Clone from GitHub\n",
        "!git clone https://github.com/Anastasia-Deniz/project-aether.git\n",
        "%cd project-aether\n",
        "\n",
        "# Option B: If you uploaded files manually:\n",
        "# %cd /content/project-aether\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Verify GPU and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Verify GPU\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "\n",
        "# Add project to path\n",
        "sys.path.insert(0, str(Path.cwd()))\n",
        "\n",
        "# Create necessary directories\n",
        "!mkdir -p data/latents checkpoints/probes outputs/ppo outputs/evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Phase 1 - Collect Latents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect latents for probe training\n",
        "# Colab T4 has 16GB VRAM, so we can use larger batch sizes\n",
        "# Using --hard_only and higher threshold for better probe accuracy (target: >85%)\n",
        "!python scripts/collect_latents.py \\\n",
        "    --num_samples 150 \\\n",
        "    --num_steps 8 \\\n",
        "    --device cuda \\\n",
        "    --min_inappropriate_pct 70.0 \\\n",
        "    --hard_only\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Phase 1 - Train Probes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train linear probes\n",
        "# Find the latest latents directory\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "latents_dirs = sorted(Path('data/latents').glob('run_*'), key=os.path.getmtime)\n",
        "if latents_dirs:\n",
        "    latest_latents = latents_dirs[-1]\n",
        "    print(f\"Using latents from: {latest_latents}\")\n",
        "    !python scripts/train_probes.py --latents_dir {latest_latents}\n",
        "else:\n",
        "    print(\"No latents found! Run Step 4 first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Phase 2 - Train PPO Policy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train PPO policy with Colab-optimized config\n",
        "# Colab T4 can handle larger batch sizes than RTX 4050\n",
        "# The config uses probe_path: \"auto\" to automatically find the latest probe\n",
        "!python scripts/train_ppo.py --config configs/colab_optimized.yaml\n",
        "\n",
        "# Alternative: Manually specify probe path\n",
        "# import os\n",
        "# from pathlib import Path\n",
        "# probe_dirs = sorted(Path('checkpoints/probes').glob('run_*'), key=os.path.getmtime)\n",
        "# if probe_dirs:\n",
        "#     latest_probe = probe_dirs[-1] / 'pytorch'\n",
        "#     !python scripts/train_ppo.py --config configs/colab_optimized.yaml --probe_path {latest_probe}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Phase 3 - Evaluate Policy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate trained policy\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Find latest policy and probe\n",
        "ppo_dirs = sorted(Path('outputs/ppo').glob('aether_ppo_*'), key=os.path.getmtime)\n",
        "probe_dirs = sorted(Path('checkpoints/probes').glob('run_*'), key=os.path.getmtime)\n",
        "\n",
        "if ppo_dirs and probe_dirs:\n",
        "    latest_policy = ppo_dirs[-1] / 'final_policy.pt'\n",
        "    latest_probe = probe_dirs[-1] / 'pytorch'\n",
        "    \n",
        "    if latest_policy.exists() and latest_probe.exists():\n",
        "        print(f\"Evaluating: {latest_policy}\")\n",
        "        print(f\"Using probe: {latest_probe}\")\n",
        "        !python scripts/evaluate_ppo.py \\\n",
        "            --policy_path {latest_policy} \\\n",
        "            --probe_path {latest_probe} \\\n",
        "            --num_samples 30 \\\n",
        "            --device cuda\n",
        "    else:\n",
        "        print(f\"Policy exists: {latest_policy.exists()}\")\n",
        "        print(f\"Probe exists: {latest_probe.exists()}\")\n",
        "else:\n",
        "    if not ppo_dirs:\n",
        "        print(\"No training runs found!\")\n",
        "    if not probe_dirs:\n",
        "        print(\"No probe directories found!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Results to Google Drive\n",
        "\n",
        "Mount your Google Drive and save results:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copy results to Drive\n",
        "drive_path = '/content/drive/MyDrive/project-aether-results'\n",
        "!mkdir -p {drive_path}\n",
        "\n",
        "!cp -r outputs {drive_path}/\n",
        "!cp -r checkpoints {drive_path}/\n",
        "!cp -r data/latents {drive_path}/\n",
        "\n",
        "print(f\"Results saved to: {drive_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
